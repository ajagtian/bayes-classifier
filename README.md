HW1, Naive Bayes, CSCI 544

--------------------------------

*** Please consider the files that were reuqired to be submitted, other scripts were developed as helper scripts to do score calculations and other stuff.***

#### PART 1 ####

* nbtrain.py - creates a trainging file from directory of learning examples.
* nblearn.py - learns from a training file to create model file.
* nbclassify.py - classifies files as some class, based on learning.

* all scripts take command line arguments as per the specification document. Other utility scripts print their usage on wrong use.

#### PART 2 ####

------------------------
* SVMLite implementation
------------------------

### PART 3 ###
> What are the precision, recall and F-score on the development data for your classifier in part I for each of the two datasets. Report precision, recall and F-score for each label.


--------------------------
PART 1 - Scores on dev set
-------------------------
SPAM:

	precision: 0.9701897018970189
	recall: 0.9701897018970189
	f_score: 0.9701897018970189

HAM:
	
	precision: 0.9949698189134809
	recall: 0.9949698189134809
	f_score: 0.9949698189134809


--------------------------
PART 2 - Scores on dev set
-------------------------
SPAM:

	precision: 0.9789156626506024
	recall: 0.9789156626506024
	f_score: 0.9789156626506024


HAM:
	
	precision: 0.9631425800193987
	recall: 0.9631425800193987
	f_score: 0.9631425800193987
